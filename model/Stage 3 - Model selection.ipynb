{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "RND_STATE = 100412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_name):\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(file_name)\n",
    "    with open(file_name, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "    return pickle.loads(bytes_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(file_name, data_to_save):\n",
    "    n_bytes = 2**31\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(data_to_save)\n",
    "    with open(file_name, 'w+b') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_FOLDER = '../data/dictionaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PICKLE = '../data/merged_data.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_CLF = '../data/best_clf.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file(DATA_PICKLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[data['origin'] == 'ALB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bulhakovdmytro/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "data2['average_wind_speed'].fillna((data2['average_wind_speed'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_preprocessing(data_df):\n",
    "    data_info = data_df.copy()\n",
    "    data_info = data_info.drop(['cancellation_code', 'cancelled', 'carrier_delay', 'dep_delay_new', 'late_aircraft_delay', 'nas_delay', 'security_delay', 'weather_delay', 'diverted', 'origin_city_name', 'dest_city_name'], axis = 1)\n",
    "    \n",
    "    data_info = data_info.drop(['snowfall', 'snow_depth', 'thunder', 'dust', 'haze', 'snow', 'fog', 'hail', 'damaging_wind'], axis = 1)\n",
    "    \n",
    "    data_info['crs_dep_time'] = list(map(int, working_df['crs_dep_time'].values / 100))    \n",
    "    return data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = additional_preprocessing(working_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_group = data[['status', 'carrier']]\n",
    "airlines_group_num = airlines_group.groupby(['carrier']).size()\n",
    "airlines_group = data[['status', 'carrier']]\n",
    "airlines_group = airlines_group[(airlines_group['status'] != 'no_delay')]\n",
    "airlines_group_delays_num = airlines_group.groupby(['carrier']).size()\n",
    "delay_info = pd.DataFrame({'Carrier': np.unique(airlines_group.carrier.values), 'Number of flights': airlines_group_num.values, 'Number of delays': airlines_group_delays_num.values})\n",
    "delay_info['Delay index'] = delay_info['Number of delays'] / delay_info['Number of flights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_airline_delay_index(carrier):\n",
    "    return delay_info[delay_info['Carrier'] == carrier]['Delay index'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_df):\n",
    "    data_info = data_df.copy()\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor(16) as pool:\n",
    "        data_info['airline_delay_index'] = list(pool.map(add_airline_delay_index, data_info['carrier'], chunksize=1_000))\n",
    "    \n",
    "    data_info = pd.get_dummies(data_info, columns=['dest'])\n",
    "    data_info['day_of_year'] = (data_info['fl_date'] - data_info['fl_date'].min())  / np.timedelta64(1,'D')\n",
    "    \n",
    "        \n",
    "    # data_info['crs_dep_time_time_sin'] = np.sin(2*np.pi*data_info.crs_dep_time/24.)\n",
    "    # data_info['crs_dep_time_time_cos'] = np.cos(2*np.pi*data_info.crs_dep_time/24.)\n",
    "    \n",
    "    data_info['weekend'] = np.where(data_info['day_of_week'] >= 6, 1, 0)\n",
    "    \n",
    "    data_info = data_info.drop(['fl_date', 'fl_num', 'origin', 'tail_num', 'carrier'], axis=1)\n",
    "    return data_info, data_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df, tmp = process_data(working_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(working_df.loc[:, working_df.columns != 'status'], working_df['status'], test_size = 0.2, random_state = RND_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester():\n",
    "    def __init__(self, parameters, model, scoring='f1_macro', njobs=-1, cv=3):\n",
    "        self.cv = GridSearchCV(model, param_grid=parameters, scoring = scoring, n_jobs = njobs, cv = cv, verbose = 1)\n",
    "    \n",
    "    def test_model(self, Xtrain, ytrain, Xtest, ytest):\n",
    "        self.cv.fit(Xtrain, ytrain);\n",
    "        print('Best score cv: ', self.cv.best_score_)\n",
    "        print('Params: ', self.cv.best_params_)\n",
    "    \n",
    "        y_predicted = self.cv.predict(Xtest)\n",
    "        print('F1 (micro) score on test sample:', f1_score(ytest, y_predicted, average='micro'))\n",
    "        print('F1 (weighted) score on test sample:', f1_score(ytest, y_predicted, average='weighted'))\n",
    "        \n",
    "    def best_estimator(self):\n",
    "        return self.cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1728 candidates, totalling 5184 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.8min\n"
     ]
    }
   ],
   "source": [
    "param = {'criterion':['gini', 'entropy'], 'max_features':[1, 2, 3, 4, 5, 6, 7, 'log2', 'auto'],\n",
    "         'max_depth':[2, 4, 8, 16, 32, 64], 'class_weight':['balanced', None], 'n_estimators': [30, 40, 50, 60], 'bootstrap': [True, False]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = RandomForestClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "rf_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Random Forest Classifier', 'clf': rf_clf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = rf_clf.predict(X_test)\n",
    "print('F1 (micro) score on test sample:', f1_score(y_test, y_predicted, average='macro'))\n",
    "print('F1 (macro) score on test sample:', f1_score(y_test, y_predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'C': np.linspace(0.01, 0.03, num=2), \n",
    "              'class_weight':['balanced', None], 'kernel':['linear'],\n",
    "              'decision_function_shape' : ['ovo', 'ovr', None]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = SVC(random_state=RND_STATE, cache_size=2048))\n",
    "# mt.test_model(X_train, y_train, X_test, y_test)\n",
    "# svc_clf = mt.best_estimator()\n",
    "# classifiers.append({'name': 'SVC', 'clf': svc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'algorithm': ['SAMME.R', 'SAMME'], 'learning_rate': [0.1, 0.3, 0.6, 0.8, 1.0]}\n",
    "mt = ModelTester(parameters = param, model = AdaBoostClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "adc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'AdaBoost Classifier', 'clf': adc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], \n",
    "         'class_weight' : ['balanced'], 'random_state':[RND_STATE], 'presort':[True, False]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = DecisionTreeClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "dtc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Decision Tree Classifier', 'clf': dtc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_neighbors': [30, 50, 65, 70], 'weights': ['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "         'leaf_size' : [10, 15, 20], 'p':[1, 2]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = KNeighborsClassifier())\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "knn_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'K-Neighbors Classifier', 'clf': knn_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'loss': ['deviance'], 'max_features':[1, 2, 3, 4, 5, 'log2', 'auto'], 'presort':[True, False],\n",
    "         'n_estimators':[200, 300], 'min_samples_leaf' : [3]}\n",
    "\n",
    "mt = ModelTester(parameters = param, model = GradientBoostingClassifier(random_state=RND_STATE))\n",
    "mt.test_model(X_train, y_train, X_test, y_test)\n",
    "gbc_clf = mt.best_estimator()\n",
    "classifiers.append({'name': 'Gradient Boosting Classifier', 'clf': gbc_clf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results per classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_importances_internal(data_df, imp_list):\n",
    "    print('Top 10 features:')\n",
    "    val_zip = zip(data_df.columns, imp_list) \n",
    "    for a, b, in sorted(val_zip, key = lambda zp_gb: zp_gb[1], reverse = True)[:10]:\n",
    "        print(\"{0}: {1}\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_importances(data_df, model):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print_importances_internal(data_df, model.feature_importances_)\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print_importances_internal(data_df, model.coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "for clf in log_progress(classifiers, every = 1):\n",
    "    print('\\n' + clf['name'])\n",
    "    score = f1_score(clf['clf'].predict(X_test), y_test, average='weighted')\n",
    "    print('F1 score: ', score)\n",
    "    results_data.append({'Classifier': clf['name'], 'F1 Score': score})\n",
    "    print_importances(working_df.loc[:, working_df.columns != 'status'], clf['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
